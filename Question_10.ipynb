{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/cs21s006/cs6910_assignment1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiLMED6CWnA1",
        "outputId": "87912922-7bd2-402d-d22c-06f8fa7023de"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cs6910_assignment1'...\n",
            "remote: Enumerating objects: 104, done.\u001b[K\n",
            "remote: Counting objects: 100% (104/104), done.\u001b[K\n",
            "remote: Compressing objects: 100% (83/83), done.\u001b[K\n",
            "remote: Total 104 (delta 40), reused 49 (delta 16), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (104/104), 61.09 KiB | 1.00 MiB/s, done.\n",
            "Resolving deltas: 100% (40/40), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd cs6910_assignment1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMvPj5aIW2aL",
        "outputId": "e9d36970-66e0-49c2-eee4-15a4f4b3401c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cs6910_assignment1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxgKuGiDW3wI",
        "outputId": "df7da489-5fd8-47a9-e4d5-8cac4d0f12e2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.12.10-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[?25l\r\u001b[K     |▏                               | 10 kB 23.9 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 25.9 MB/s eta 0:00:01\r\u001b[K     |▋                               | 30 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |▊                               | 40 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█                               | 51 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 61 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 71 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 81 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 92 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 102 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██                              | 112 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 122 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 133 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 143 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 153 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 163 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 174 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 184 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 194 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 204 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████                            | 215 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 225 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 235 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 245 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 256 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████                           | 266 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 276 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 286 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 296 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 307 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 317 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 327 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 337 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 348 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 358 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 368 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████                         | 378 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 389 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 399 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 409 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 419 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████                        | 430 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 440 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 450 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 460 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 471 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 481 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 491 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 501 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 512 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 522 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 532 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 542 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 552 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 563 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 573 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 583 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 593 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 604 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 614 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 624 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 634 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 645 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 655 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 665 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 675 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 686 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 696 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 706 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 716 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 727 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 737 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 747 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 757 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 768 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 778 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 788 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 798 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 808 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 819 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 829 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 839 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 849 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 860 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 870 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 880 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 890 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 901 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 911 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 921 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 931 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 942 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 952 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 962 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 972 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 983 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 993 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.0 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.0 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.0 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.0 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.0 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.1 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.1 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.1 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.1 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.1 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.1 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.1 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.1 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.1 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.2 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.2 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.2 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.2 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.2 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.2 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.2 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.2 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.3 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.3 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.3 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.3 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.3 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.3 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.3 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.3 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.3 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.4 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.4 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.4 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.4 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.4 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.4 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.4 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.4 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.4 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.4 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.5 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.5 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.5 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.5 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.5 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.5 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.5 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.5 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.5 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.5 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.6 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.6 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.6 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.6 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.6 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.6 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.6 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.6 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.6 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.6 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.7 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.7 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.7 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.7 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.7 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.7 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.7 MB 8.5 MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 59.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Collecting yaspin>=1.0.0\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.5-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 57.3 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=67ebbe867c22cfb3e1b0c834d639abc507f2e4afc6df738345406907170f26fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, yaspin, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.5 shortuuid-1.0.8 smmap-5.0.0 wandb-0.12.10 yaspin-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#configuration 1\n",
        "!python train.py -p 'cs6910_assignment1_mnist' \\\n",
        "    -d 'mnist' \\\n",
        "    -e 20 \\\n",
        "    -b 128 \\\n",
        "    -l 'cross_entropy' \\\n",
        "    -o 'adam' \\\n",
        "    -lr 0.0001 \\\n",
        "    -w_i 'He_normal' \\\n",
        "    -w_d .0 \\\n",
        "    -nhl 4 \\\n",
        "    -sz 256 \\\n",
        "    -a 'tanh'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-AmRyY9j3sF",
        "outputId": "350f0e1f-0c1e-40f2-c2d0-8e94544fe3b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running:  e=20_b=128_o=adam_lr=0.0001_hl=4_sz=256_a=tanh_w_i=He_normal_w_d=0.0_l=ce\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs21s006_cs21s043\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33me=20_b=128_o=adam_lr=0.0001_hl=4_sz=256_a=tanh_w_i=He_normal_w_d=0.0_l=ce\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/cs21s006_cs21s043/cs6910_assignment1_mnist\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/cs21s006_cs21s043/cs6910_assignment1_mnist/runs/3gvtn8ev\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/cs6910_assignment1/wandb/run-20220221_091558-3gvtn8ev\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "(54000, 784) (54000, 10) (10000, 784) (10000, 10) (6000, 784) (6000, 10)\n",
            "epoch: 0, lr: 0.00010 | loss: 0.0173, acc(batch): 0.9464, grad:106719.3075: : 422it [00:42,  9.82it/s]           \n",
            "acc(train): 0.9345, acc(val): 0.9368, acc(test): 0.9337\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 1, lr: 0.00010 | loss: 0.0127, acc(batch): 0.9643, grad:105315.3964: : 422it [00:43,  9.78it/s]           \n",
            "acc(train): 0.9514, acc(val): 0.9522, acc(test): 0.9469\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 2, lr: 0.00010 | loss: 0.0098, acc(batch): 0.9821, grad:105215.4374: : 422it [00:43,  9.75it/s]\n",
            "acc(train): 0.9619, acc(val): 0.9603, acc(test): 0.9563\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 3, lr: 0.00010 | loss: 0.0075, acc(batch): 0.9821, grad:105355.7168: : 422it [00:42,  9.92it/s]           \n",
            "acc(train): 0.9689, acc(val): 0.9653, acc(test): 0.9612\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 4, lr: 0.00010 | loss: 0.0059, acc(batch): 0.9821, grad:105811.6718: : 422it [00:43,  9.75it/s]\n",
            "acc(train): 0.9738, acc(val): 0.9680, acc(test): 0.9639\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 5, lr: 0.00010 | loss: 0.0046, acc(batch): 0.9911, grad:106295.0268: : 422it [00:42,  9.93it/s]           \n",
            "acc(train): 0.9775, acc(val): 0.9697, acc(test): 0.9668\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 6, lr: 0.00010 | loss: 0.0037, acc(batch): 0.9911, grad:106732.8668: : 422it [00:43,  9.68it/s]\n",
            "acc(train): 0.9810, acc(val): 0.9708, acc(test): 0.9683\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 7, lr: 0.00010 | loss: 0.0031, acc(batch): 1.0000, grad:106693.9336: : 422it [00:43,  9.68it/s]\n",
            "acc(train): 0.9834, acc(val): 0.9717, acc(test): 0.9706\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 8, lr: 0.00010 | loss: 0.0026, acc(batch): 1.0000, grad:106138.7006: : 422it [00:43,  9.68it/s]\n",
            "acc(train): 0.9858, acc(val): 0.9718, acc(test): 0.9719\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 9, lr: 0.00010 | loss: 0.0023, acc(batch): 1.0000, grad:105638.7025: : 422it [00:43,  9.65it/s]\n",
            "acc(train): 0.9876, acc(val): 0.9733, acc(test): 0.9725\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 10, lr: 0.00010 | loss: 0.0020, acc(batch): 1.0000, grad:105227.7321: : 422it [00:43,  9.63it/s]           \n",
            "acc(train): 0.9890, acc(val): 0.9747, acc(test): 0.9732\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 11, lr: 0.00010 | loss: 0.0017, acc(batch): 1.0000, grad:104777.1527: : 422it [00:43,  9.63it/s]\n",
            "acc(train): 0.9903, acc(val): 0.9750, acc(test): 0.9734\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 12, lr: 0.00010 | loss: 0.0015, acc(batch): 1.0000, grad:104242.5305: : 422it [00:43,  9.66it/s]           \n",
            "acc(train): 0.9914, acc(val): 0.9755, acc(test): 0.9737\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 13, lr: 0.00010 | loss: 0.0013, acc(batch): 1.0000, grad:103660.9913: : 422it [00:43,  9.63it/s]\n",
            "acc(train): 0.9925, acc(val): 0.9760, acc(test): 0.9744\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 14, lr: 0.00010 | loss: 0.0011, acc(batch): 1.0000, grad:103095.5296: : 422it [00:43,  9.60it/s]           \n",
            "acc(train): 0.9933, acc(val): 0.9758, acc(test): 0.9747\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 15, lr: 0.00010 | loss: 0.0009, acc(batch): 1.0000, grad:102587.0137: : 422it [00:43,  9.65it/s]\n",
            "acc(train): 0.9939, acc(val): 0.9757, acc(test): 0.9751\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 16, lr: 0.00010 | loss: 0.0006, acc(batch): 1.0000, grad:102072.5740: : 422it [00:43,  9.65it/s]\n",
            "acc(train): 0.9947, acc(val): 0.9760, acc(test): 0.9757\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 17, lr: 0.00010 | loss: 0.0004, acc(batch): 1.0000, grad:101778.6348: : 422it [00:43,  9.66it/s]           \n",
            "acc(train): 0.9951, acc(val): 0.9763, acc(test): 0.9758\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 18, lr: 0.00010 | loss: 0.0002, acc(batch): 1.0000, grad:101834.1540: : 422it [00:43,  9.66it/s]\n",
            "acc(train): 0.9954, acc(val): 0.9762, acc(test): 0.9758\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 19, lr: 0.00010 | loss: 0.0001, acc(batch): 1.0000, grad:102328.7405: : 422it [00:44,  9.57it/s]\n",
            "acc(train): 0.9958, acc(val): 0.9762, acc(test): 0.9763\n",
            "___________________________________________________________________________________________________\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 443... (success).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch ▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_acc ▁▃▅▆▆▆▇▇▇▇▇█████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    train_acc ▁▃▄▅▅▆▆▇▇▇▇▇▇███████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train_loss █▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      val_acc ▁▄▅▆▇▇▇▇▇▇██████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     val_loss █▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch 19\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_acc 0.9763\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    train_acc 0.99583\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train_loss 0.00137\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      val_acc 0.97617\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     val_loss 0.00968\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33me=20_b=128_o=adam_lr=0.0001_hl=4_sz=256_a=tanh_w_i=He_normal_w_d=0.0_l=ce\u001b[0m: \u001b[34mhttps://wandb.ai/cs21s006_cs21s043/cs6910_assignment1_mnist/runs/3gvtn8ev\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: ./wandb/run-20220221_091558-3gvtn8ev/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#configuration 2\n",
        "!python train.py -p 'cs6910_assignment1_mnist' \\\n",
        "    -d 'mnist' \\\n",
        "    -e 20 \\\n",
        "    -b 64 \\\n",
        "    -l 'cross_entropy' \\\n",
        "    -o 'adam' \\\n",
        "    -lr 0.0001 \\\n",
        "    -w_i 'He_normal' \\\n",
        "    -w_d .0 \\\n",
        "    -nhl 4 \\\n",
        "    -sz 256 \\\n",
        "    -a 'tanh'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQnBeX7c6gDi",
        "outputId": "2a8043ec-2751-4bb1-917b-87002d212a7b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running:  e=20_b=64_o=adam_lr=0.0001_hl=4_sz=256_a=tanh_w_i=He_normal_w_d=0.0_l=ce\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33me=20_b=64_o=adam_lr=0.0001_hl=4_sz=256_a=tanh_w_i=He_normal_w_d=0.0_l=ce\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/cs21s006_cs21s043/cs6910_assignment1_mnist\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/cs21s006_cs21s043/cs6910_assignment1_mnist/runs/22cklh32\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/cs6910_assignment1/wandb/run-20220222_101331-22cklh32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "(54000, 784) (54000, 10) (10000, 784) (10000, 10) (6000, 784) (6000, 10)\n",
            "epoch: 0, lr: 0.00010 | loss: 0.0087, acc(batch): 1.0000, grad:107573.3879: : 844it [01:08, 12.24it/s]\n",
            "acc(train): 0.9416, acc(val): 0.9438, acc(test): 0.9393\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 1, lr: 0.00010 | loss: 0.0052, acc(batch): 1.0000, grad:107106.3387: : 844it [01:08, 12.40it/s]\n",
            "acc(train): 0.9583, acc(val): 0.9565, acc(test): 0.9540\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 2, lr: 0.00010 | loss: 0.0030, acc(batch): 1.0000, grad:106688.2728: : 844it [01:09, 12.10it/s]\n",
            "acc(train): 0.9688, acc(val): 0.9652, acc(test): 0.9609\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 3, lr: 0.00010 | loss: 0.0016, acc(batch): 1.0000, grad:105686.2273: : 844it [01:08, 12.27it/s]\n",
            "acc(train): 0.9750, acc(val): 0.9685, acc(test): 0.9649\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 4, lr: 0.00010 | loss: 0.0008, acc(batch): 1.0000, grad:105259.7797: : 844it [01:09, 12.07it/s]\n",
            "acc(train): 0.9792, acc(val): 0.9712, acc(test): 0.9670\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 5, lr: 0.00010 | loss: 0.0004, acc(batch): 1.0000, grad:104796.4917: : 844it [01:07, 12.60it/s]\n",
            "acc(train): 0.9823, acc(val): 0.9725, acc(test): 0.9704\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 6, lr: 0.00010 | loss: 0.0002, acc(batch): 1.0000, grad:104712.7171: : 844it [01:09, 12.16it/s]\n",
            "acc(train): 0.9847, acc(val): 0.9735, acc(test): 0.9715\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 7, lr: 0.00010 | loss: 0.0001, acc(batch): 1.0000, grad:105225.6150: : 844it [01:09, 12.20it/s]\n",
            "acc(train): 0.9868, acc(val): 0.9740, acc(test): 0.9729\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 8, lr: 0.00010 | loss: 0.0000, acc(batch): 1.0000, grad:105641.4965: : 844it [01:08, 12.25it/s]\n",
            "acc(train): 0.9885, acc(val): 0.9752, acc(test): 0.9738\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 9, lr: 0.00010 | loss: 0.0000, acc(batch): 1.0000, grad:106333.3046: : 844it [01:08, 12.25it/s]\n",
            "acc(train): 0.9895, acc(val): 0.9757, acc(test): 0.9741\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 10, lr: 0.00010 | loss: 0.0000, acc(batch): 1.0000, grad:106483.9894: : 844it [01:08, 12.28it/s]\n",
            "acc(train): 0.9907, acc(val): 0.9750, acc(test): 0.9753\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 11, lr: 0.00010 | loss: 0.0000, acc(batch): 1.0000, grad:106374.9124: : 844it [01:08, 12.29it/s]\n",
            "acc(train): 0.9916, acc(val): 0.9755, acc(test): 0.9758\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 12, lr: 0.00010 | loss: 0.0000, acc(batch): 1.0000, grad:105943.4357: : 844it [01:08, 12.24it/s]\n",
            "acc(train): 0.9923, acc(val): 0.9765, acc(test): 0.9766\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 13, lr: 0.00010 | loss: 0.0000, acc(batch): 1.0000, grad:104942.4748: : 844it [01:10, 11.99it/s]           \n",
            "acc(train): 0.9933, acc(val): 0.9770, acc(test): 0.9755\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 14, lr: 0.00010 | loss: 0.0000, acc(batch): 1.0000, grad:103563.5143: : 844it [01:08, 12.27it/s]\n",
            "acc(train): 0.9942, acc(val): 0.9790, acc(test): 0.9762\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 15, lr: 0.00010 | loss: 0.0000, acc(batch): 1.0000, grad:106272.0516: : 844it [01:09, 12.06it/s]\n",
            "acc(train): 0.9945, acc(val): 0.9783, acc(test): 0.9765\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 16, lr: 0.00010 | loss: 0.0000, acc(batch): 1.0000, grad:109786.5214: : 844it [01:09, 12.23it/s]\n",
            "acc(train): 0.9947, acc(val): 0.9782, acc(test): 0.9765\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 17, lr: 0.00010 | loss: 0.0000, acc(batch): 1.0000, grad:109277.8869: : 844it [01:10, 11.95it/s]\n",
            "acc(train): 0.9951, acc(val): 0.9787, acc(test): 0.9768\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 18, lr: 0.00010 | loss: 0.0000, acc(batch): 1.0000, grad:109267.4501: : 844it [01:08, 12.30it/s]\n",
            "acc(train): 0.9955, acc(val): 0.9778, acc(test): 0.9770\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 19, lr: 0.00010 | loss: 0.0000, acc(batch): 1.0000, grad:109124.7041: : 844it [01:09, 12.06it/s]\n",
            "acc(train): 0.9957, acc(val): 0.9778, acc(test): 0.9771\n",
            "___________________________________________________________________________________________________\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 210... (success).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch ▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_acc ▁▄▅▆▆▇▇▇▇▇██████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    train_acc ▁▃▅▅▆▆▇▇▇▇▇▇████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train_loss █▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      val_acc ▁▄▅▆▆▇▇▇▇▇▇▇████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     val_loss █▅▃▂▂▁▁▁▁▁▁▁▂▂▂▃▃▃▃▃\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch 19\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_acc 0.9771\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    train_acc 0.9957\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train_loss 0.00195\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      val_acc 0.97783\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     val_loss 0.01255\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33me=20_b=64_o=adam_lr=0.0001_hl=4_sz=256_a=tanh_w_i=He_normal_w_d=0.0_l=ce\u001b[0m: \u001b[34mhttps://wandb.ai/cs21s006_cs21s043/cs6910_assignment1_mnist/runs/22cklh32\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: ./wandb/run-20220222_101331-22cklh32/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#configuration 3\n",
        "!python train.py -p 'cs6910_assignment1_mnist' \\\n",
        "    -d 'mnist' \\\n",
        "    -e 20 \\\n",
        "    -b 128 \\\n",
        "    -l 'cross_entropy' \\\n",
        "    -o 'nadam' \\\n",
        "    -lr 0.0001 \\\n",
        "    -w_i 'He_normal' \\\n",
        "    -w_d .0 \\\n",
        "    -nhl 4 \\\n",
        "    -sz 256 \\\n",
        "    -a 'tanh'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhoihVaa6qBX",
        "outputId": "382d5904-c9f0-4071-cdb7-2db20985a779"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running:  e=20_b=128_o=nadam_lr=0.0001_hl=4_sz=256_a=tanh_w_i=He_normal_w_d=0.0_l=ce\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs21s006_cs21s043\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33me=20_b=128_o=nadam_lr=0.0001_hl=4_sz=256_a=tanh_w_i=He_normal_w_d=0.0_l=ce\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/cs21s006_cs21s043/cs6910_assignment1_mnist\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/cs21s006_cs21s043/cs6910_assignment1_mnist/runs/cdx5e36x\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/cs6910_assignment1/wandb/run-20220222_104731-cdx5e36x\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "(54000, 784) (54000, 10) (10000, 784) (10000, 10) (6000, 784) (6000, 10)\n",
            "epoch: 0, lr: 0.00010 | loss: 0.0172, acc(batch): 0.9464, grad:106890.5367: : 422it [00:38, 11.04it/s]\n",
            "acc(train): 0.9346, acc(val): 0.9372, acc(test): 0.9341\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 1, lr: 0.00010 | loss: 0.0126, acc(batch): 0.9643, grad:105536.7575: : 422it [00:38, 10.94it/s]\n",
            "acc(train): 0.9517, acc(val): 0.9525, acc(test): 0.9483\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 2, lr: 0.00010 | loss: 0.0096, acc(batch): 0.9821, grad:105307.1119: : 422it [00:39, 10.78it/s]\n",
            "acc(train): 0.9621, acc(val): 0.9605, acc(test): 0.9562\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 3, lr: 0.00010 | loss: 0.0073, acc(batch): 0.9821, grad:105307.9380: : 422it [00:39, 10.72it/s]\n",
            "acc(train): 0.9690, acc(val): 0.9653, acc(test): 0.9613\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 4, lr: 0.00010 | loss: 0.0056, acc(batch): 0.9821, grad:105834.0535: : 422it [00:39, 10.77it/s]\n",
            "acc(train): 0.9739, acc(val): 0.9673, acc(test): 0.9648\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 5, lr: 0.00010 | loss: 0.0044, acc(batch): 0.9911, grad:106370.1340: : 422it [00:38, 10.84it/s]\n",
            "acc(train): 0.9779, acc(val): 0.9693, acc(test): 0.9677\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 6, lr: 0.00010 | loss: 0.0035, acc(batch): 0.9911, grad:106781.7375: : 422it [00:38, 10.84it/s]\n",
            "acc(train): 0.9810, acc(val): 0.9708, acc(test): 0.9685\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 7, lr: 0.00010 | loss: 0.0029, acc(batch): 1.0000, grad:106731.2050: : 422it [00:38, 10.84it/s]\n",
            "acc(train): 0.9836, acc(val): 0.9713, acc(test): 0.9705\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 8, lr: 0.00010 | loss: 0.0025, acc(batch): 1.0000, grad:106165.2671: : 422it [00:39, 10.74it/s]\n",
            "acc(train): 0.9859, acc(val): 0.9720, acc(test): 0.9717\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 9, lr: 0.00010 | loss: 0.0022, acc(batch): 1.0000, grad:105602.4285: : 422it [00:39, 10.76it/s]\n",
            "acc(train): 0.9876, acc(val): 0.9733, acc(test): 0.9726\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 10, lr: 0.00010 | loss: 0.0019, acc(batch): 1.0000, grad:105163.1472: : 422it [00:39, 10.82it/s]\n",
            "acc(train): 0.9891, acc(val): 0.9742, acc(test): 0.9733\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 11, lr: 0.00010 | loss: 0.0016, acc(batch): 1.0000, grad:104690.2985: : 422it [00:39, 10.82it/s]\n",
            "acc(train): 0.9905, acc(val): 0.9752, acc(test): 0.9733\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 12, lr: 0.00010 | loss: 0.0014, acc(batch): 1.0000, grad:104124.1356: : 422it [00:38, 10.89it/s]\n",
            "acc(train): 0.9916, acc(val): 0.9755, acc(test): 0.9738\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 13, lr: 0.00010 | loss: 0.0012, acc(batch): 1.0000, grad:103570.9655: : 422it [00:38, 10.99it/s]\n",
            "acc(train): 0.9927, acc(val): 0.9757, acc(test): 0.9740\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 14, lr: 0.00010 | loss: 0.0010, acc(batch): 1.0000, grad:103168.0809: : 422it [00:39, 10.73it/s]           \n",
            "acc(train): 0.9936, acc(val): 0.9760, acc(test): 0.9745\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 15, lr: 0.00010 | loss: 0.0008, acc(batch): 1.0000, grad:102838.8178: : 422it [00:39, 10.74it/s]\n",
            "acc(train): 0.9941, acc(val): 0.9762, acc(test): 0.9748\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 16, lr: 0.00010 | loss: 0.0006, acc(batch): 1.0000, grad:102563.6567: : 422it [00:39, 10.78it/s]\n",
            "acc(train): 0.9949, acc(val): 0.9767, acc(test): 0.9757\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 17, lr: 0.00010 | loss: 0.0004, acc(batch): 1.0000, grad:102469.9298: : 422it [00:39, 10.79it/s]\n",
            "acc(train): 0.9954, acc(val): 0.9767, acc(test): 0.9759\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 18, lr: 0.00010 | loss: 0.0002, acc(batch): 1.0000, grad:102324.2109: : 422it [00:39, 10.81it/s]\n",
            "acc(train): 0.9957, acc(val): 0.9773, acc(test): 0.9763\n",
            "___________________________________________________________________________________________________\n",
            "epoch: 19, lr: 0.00010 | loss: 0.0001, acc(batch): 1.0000, grad:102054.3432: : 422it [00:39, 10.77it/s]           \n",
            "acc(train): 0.9962, acc(val): 0.9775, acc(test): 0.9764\n",
            "___________________________________________________________________________________________________\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 332... (success).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch ▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_acc ▁▃▅▆▆▇▇▇▇▇▇▇████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    train_acc ▁▃▄▅▅▆▆▇▇▇▇▇▇███████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train_loss █▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      val_acc ▁▄▅▆▆▇▇▇▇▇▇█████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     val_loss █▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch 19\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_acc 0.9764\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    train_acc 0.99617\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train_loss 0.00136\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      val_acc 0.9775\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     val_loss 0.00951\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33me=20_b=128_o=nadam_lr=0.0001_hl=4_sz=256_a=tanh_w_i=He_normal_w_d=0.0_l=ce\u001b[0m: \u001b[34mhttps://wandb.ai/cs21s006_cs21s043/cs6910_assignment1_mnist/runs/cdx5e36x\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: ./wandb/run-20220222_104731-cdx5e36x/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Dmr5BAU8CwQx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "edf89f71fd1e23cd0151d7a14b12878cc02def8a7ebd99b40844038cba8a62d2"
    },
    "kernelspec": {
      "display_name": "Python 3.10.0 ('tf2')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Question_10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}